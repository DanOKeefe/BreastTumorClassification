{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('BreastCancer.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_largest_worst</th>\n",
       "      <th>texture_largest_worst</th>\n",
       "      <th>perimeter_largest_worst</th>\n",
       "      <th>area_largest_worst</th>\n",
       "      <th>smoothness_largest_worst</th>\n",
       "      <th>compactness_largest_worst</th>\n",
       "      <th>concavity_largest_worst</th>\n",
       "      <th>concave_points_largest_worst</th>\n",
       "      <th>symmetry_largest_worst</th>\n",
       "      <th>fractal_dimension_largest_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>-0.078686</td>\n",
       "      <td>-0.483523</td>\n",
       "      <td>-0.145234</td>\n",
       "      <td>-0.188083</td>\n",
       "      <td>-0.605105</td>\n",
       "      <td>-0.813837</td>\n",
       "      <td>-0.935769</td>\n",
       "      <td>-0.966660</td>\n",
       "      <td>-0.720860</td>\n",
       "      <td>-0.552041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.161215</td>\n",
       "      <td>-0.341220</td>\n",
       "      <td>-0.207163</td>\n",
       "      <td>-0.271680</td>\n",
       "      <td>-0.730040</td>\n",
       "      <td>-0.758025</td>\n",
       "      <td>-0.915706</td>\n",
       "      <td>-0.967046</td>\n",
       "      <td>-0.867590</td>\n",
       "      <td>-0.671371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-0.674591</td>\n",
       "      <td>0.207009</td>\n",
       "      <td>-0.653074</td>\n",
       "      <td>-0.668030</td>\n",
       "      <td>0.891610</td>\n",
       "      <td>0.184785</td>\n",
       "      <td>-0.255511</td>\n",
       "      <td>-0.297379</td>\n",
       "      <td>0.661631</td>\n",
       "      <td>0.245368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.610189</td>\n",
       "      <td>0.086683</td>\n",
       "      <td>-0.546126</td>\n",
       "      <td>-0.591339</td>\n",
       "      <td>0.150287</td>\n",
       "      <td>-0.413541</td>\n",
       "      <td>-0.367112</td>\n",
       "      <td>-0.540316</td>\n",
       "      <td>0.431963</td>\n",
       "      <td>-0.225666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>3.292437</td>\n",
       "      <td>-0.425397</td>\n",
       "      <td>3.384132</td>\n",
       "      <td>3.850686</td>\n",
       "      <td>1.318227</td>\n",
       "      <td>2.498620</td>\n",
       "      <td>3.110904</td>\n",
       "      <td>3.669341</td>\n",
       "      <td>0.526665</td>\n",
       "      <td>-0.224862</td>\n",
       "      <td>...</td>\n",
       "      <td>3.488510</td>\n",
       "      <td>-0.341220</td>\n",
       "      <td>3.631832</td>\n",
       "      <td>4.133464</td>\n",
       "      <td>0.903601</td>\n",
       "      <td>2.157382</td>\n",
       "      <td>1.787479</td>\n",
       "      <td>2.449232</td>\n",
       "      <td>1.275702</td>\n",
       "      <td>0.232773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>-1.282982</td>\n",
       "      <td>-0.569549</td>\n",
       "      <td>-1.248161</td>\n",
       "      <td>-1.063865</td>\n",
       "      <td>-0.821258</td>\n",
       "      <td>-0.228373</td>\n",
       "      <td>-0.057443</td>\n",
       "      <td>-0.670032</td>\n",
       "      <td>0.818484</td>\n",
       "      <td>1.197161</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.141923</td>\n",
       "      <td>-0.424197</td>\n",
       "      <td>-1.071681</td>\n",
       "      <td>-0.925576</td>\n",
       "      <td>-0.397180</td>\n",
       "      <td>0.555084</td>\n",
       "      <td>0.776091</td>\n",
       "      <td>-0.508216</td>\n",
       "      <td>0.131320</td>\n",
       "      <td>0.791981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>-0.351099</td>\n",
       "      <td>-1.434456</td>\n",
       "      <td>-0.414792</td>\n",
       "      <td>-0.394952</td>\n",
       "      <td>-1.906288</td>\n",
       "      <td>-1.269598</td>\n",
       "      <td>-0.830400</td>\n",
       "      <td>-0.958928</td>\n",
       "      <td>-1.731282</td>\n",
       "      <td>-0.989696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.548119</td>\n",
       "      <td>-1.649333</td>\n",
       "      <td>-0.591063</td>\n",
       "      <td>-0.533203</td>\n",
       "      <td>-1.585841</td>\n",
       "      <td>-0.887048</td>\n",
       "      <td>-0.736197</td>\n",
       "      <td>-0.927188</td>\n",
       "      <td>-0.956489</td>\n",
       "      <td>-0.819201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "125    -0.078686     -0.483523       -0.145234  -0.188083        -0.605105   \n",
       "160    -0.674591      0.207009       -0.653074  -0.668030         0.891610   \n",
       "352     3.292437     -0.425397        3.384132   3.850686         1.318227   \n",
       "341    -1.282982     -0.569549       -1.248161  -1.063865        -0.821258   \n",
       "287    -0.351099     -1.434456       -0.414792  -0.394952        -1.906288   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave_points_mean  symmetry_mean  \\\n",
       "125         -0.813837       -0.935769            -0.966660      -0.720860   \n",
       "160          0.184785       -0.255511            -0.297379       0.661631   \n",
       "352          2.498620        3.110904             3.669341       0.526665   \n",
       "341         -0.228373       -0.057443            -0.670032       0.818484   \n",
       "287         -1.269598       -0.830400            -0.958928      -1.731282   \n",
       "\n",
       "     fractal_dimension_mean               ...                 \\\n",
       "125               -0.552041               ...                  \n",
       "160                0.245368               ...                  \n",
       "352               -0.224862               ...                  \n",
       "341                1.197161               ...                  \n",
       "287               -0.989696               ...                  \n",
       "\n",
       "     radius_largest_worst  texture_largest_worst  perimeter_largest_worst  \\\n",
       "125             -0.161215              -0.341220                -0.207163   \n",
       "160             -0.610189               0.086683                -0.546126   \n",
       "352              3.488510              -0.341220                 3.631832   \n",
       "341             -1.141923              -0.424197                -1.071681   \n",
       "287             -0.548119              -1.649333                -0.591063   \n",
       "\n",
       "     area_largest_worst  smoothness_largest_worst  compactness_largest_worst  \\\n",
       "125           -0.271680                 -0.730040                  -0.758025   \n",
       "160           -0.591339                  0.150287                  -0.413541   \n",
       "352            4.133464                  0.903601                   2.157382   \n",
       "341           -0.925576                 -0.397180                   0.555084   \n",
       "287           -0.533203                 -1.585841                  -0.887048   \n",
       "\n",
       "     concavity_largest_worst  concave_points_largest_worst  \\\n",
       "125                -0.915706                     -0.967046   \n",
       "160                -0.367112                     -0.540316   \n",
       "352                 1.787479                      2.449232   \n",
       "341                 0.776091                     -0.508216   \n",
       "287                -0.736197                     -0.927188   \n",
       "\n",
       "     symmetry_largest_worst  fractal_dimension_largest_worst  \n",
       "125               -0.867590                        -0.671371  \n",
       "160                0.431963                        -0.225666  \n",
       "352                1.275702                         0.232773  \n",
       "341                0.131320                         0.791981  \n",
       "287               -0.956489                        -0.819201  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X: 30 features per example (not including index which I excluded)\n",
    "# Y: diagnosis (M: Malignant, B: Benign) -> map M: 1, B: 0\n",
    "df.columns = ['index', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "              'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', \n",
    "              'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean', \n",
    "              'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', \n",
    "              'compactness_se', 'concavity_se', 'concave_points_se', 'symmetry_se', \n",
    "              'fractal_dimension_se', 'radius_largest_worst', 'texture_largest_worst', \n",
    "              'perimeter_largest_worst', 'area_largest_worst', 'smoothness_largest_worst', \n",
    "              'compactness_largest_worst', 'concavity_largest_worst', 'concave_points_largest_worst', \n",
    "              'symmetry_largest_worst', 'fractal_dimension_largest_worst']\n",
    "df = df.drop('index',axis =1)\n",
    "df = df.sample(frac=1) # shuffle the rows\n",
    "Y = df['diagnosis']\n",
    "Y = Y.map({'M': 1, 'B': 0})\n",
    "df = df.drop('diagnosis', axis=1)\n",
    "df = (df - df.mean(axis=0))/df.std(axis=0) # feature scaling\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 400\n",
      "number of test examples = 85\n",
      "X_train shape: (30, 400)\n",
      "Y_train shape: (1, 400)\n",
      "X_test shape: (30, 85)\n",
      "Y_test shape: (1, 85)\n",
      "X_cv shape: (30, 84)\n",
      "Y_cv shape: (1, 84)\n"
     ]
    }
   ],
   "source": [
    "X_train = df.iloc[0:400,:] # first 400 rows\n",
    "X_cv = df.iloc[400:484,:]\n",
    "X_test = df.iloc[484:569,:]\n",
    "\n",
    "Y_train = Y.iloc[0:400]\n",
    "Y_cv = Y.iloc[400:484]\n",
    "Y_test = Y.iloc[484:569]\n",
    "\n",
    "# convert to numpy arrays\n",
    "# let each column represent one data entry\n",
    "X_train = X_train.values.T\n",
    "X_cv = X_cv.values.T\n",
    "X_test = X_test.values.T\n",
    "Y_train = Y_train.values.T\n",
    "Y_cv = Y_cv.values.T\n",
    "Y_test = Y_test.values.T\n",
    "\n",
    "Y_train.shape = (1,400)\n",
    "Y_cv.shape = (1,84)\n",
    "Y_test.shape = (1,85)\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[1])) \n",
    "print (\"number of test examples = \" + str(X_test.shape[1])) \n",
    "print (\"X_train shape: \" + str(X_train.shape)) \n",
    "print (\"Y_train shape: \" + str(Y_train.shape)) \n",
    "print (\"X_test shape: \" + str(X_test.shape)) \n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "print (\"X_cv shape: \" + str(X_cv.shape)) \n",
    "print (\"Y_cv shape: \" + str(Y_cv.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    X = tf.placeholder(tf.float32, [n_x, None])\n",
    "    Y = tf.placeholder(tf.float32, [n_y, None])\n",
    "    return X,Y\n",
    "\n",
    "def initialize_parameters():\n",
    "    # input layer      : 30 nodes\n",
    "    # 1st hidden layer : 20 nodes\n",
    "    # 2nd hidden layer : 10 nodes\n",
    "    # output layer     : 1 node\n",
    "    \n",
    "    W1 = tf.get_variable('W1', [20,30], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.get_variable('b1', [20,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable('W2', [10,20], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    b2 = tf.get_variable('b2', [10,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable('W3', [1,10], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    b3 = tf.get_variable('b3', [1,1], initializer = tf.zeros_initializer())\n",
    "    \n",
    "    parameters = {'W1': W1,\n",
    "                 'b1': b1,\n",
    "                 'W2': W2,\n",
    "                 'b2': b2,\n",
    "                 'W3': W3,\n",
    "                 'b3': b3}\n",
    "    return parameters\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(W1,X), b1)\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1), b2)\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2), b3)\n",
    "    \n",
    "    return Z3\n",
    "\n",
    "def compute_cost(Z3, Y, parameters):\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    \n",
    "    #L2_regularization_cost = np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3))\n",
    "    \n",
    "    beta = 0.03\n",
    "    regularizers = tf.nn.l2_loss(W1) + tf.nn.l2_loss(W2) + tf.nn.l2_loss(W3)\n",
    "    cost = tf.reduce_mean(cost + beta*regularizers)\n",
    "    \n",
    "    #cost = cost + L2_regularization_cost\n",
    "    return cost\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64):\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, X_cv, Y_cv, learning_rate = 0.001,\n",
    "         num_epochs = 2000, minibatch_size = 64, print_cost = True):\n",
    "    \n",
    "    ops.reset_default_graph()\n",
    "    (n_x,m) = X_train.shape\n",
    "    n_y = Y_train.shape[0]\n",
    "    costs = []\n",
    "    \n",
    "    X, Y = create_placeholders(n_x,n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3,Y, parameters)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_cost = 0\n",
    "            num_minibatches = int(m/minibatch_size)\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n",
    "            \n",
    "            for minibatch in minibatches:\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                _, minibatch_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y})\n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print('Epoch %i cost: %f' % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0 and epoch >= 0:\n",
    "                costs.append(epoch_cost)\n",
    "        \n",
    "        plt.plot(np.squeeze(costs),lw=0.5)\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('epoch + 100')\n",
    "        plt.title('Learning rate='+str(learning_rate))\n",
    "        \n",
    "        parameters = sess.run(parameters)\n",
    "        print('parameters trained')\n",
    "        \n",
    "        \n",
    "        correct_prediction = tf.equal(tf.round(tf.sigmoid(Z3)), tf.round(Y))\n",
    "        \n",
    "        \"\"\"\n",
    "        # see if there was a type 1 error\n",
    "        ErrorType1 = tf.placeholder(tf.bool)\n",
    "        def f1(): return tf.equal(1,2) # no type 1 error\n",
    "        def f2(): return tf.cond(tf.equal(tf.round(Y), 1), f3, f2) #check if Y=1\n",
    "        def f3(): return tf.equal(1,1) # type 1 error\n",
    "        ErrorType1 = tf.cond(correct_prediction, f1, f2)\n",
    "        \n",
    "        # see if there was a Type II error\n",
    "        ErrorType2 = tf.placeholder(tf.bool)\n",
    "        def f4(): return tf.equal(1,2) # no type 2 error\n",
    "        def f5(): return tf.cond(tf.equal(tf.round(Y), 0), f6, f5) #check if Y=0\n",
    "        def f6(): return tf.equal(1,1) # type 2 error\n",
    "        ErrorType2 = tf.cond(correct_prediction, f4, f5)\n",
    "        \n",
    "        \n",
    "        Type1Error = tf.reduce_mean(tf.cast(ErrorType1, 'float'))\n",
    "        Type2Error = tf.reduce_mean(tf.cast(ErrorType2, 'float'))\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"Train T1E:\", Type1Error.eval({X: X_train, Y: Y_train}))\n",
    "        print(\"Cross_val T1E:\", Type1Error.eval({X: X_cv, Y: Y_cv}))\n",
    "        print(\"Test T1E:\",  Type1Error.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        print(\"Train T2E:\", Type2Error.eval({X: X_train, Y: Y_train}))\n",
    "        print(\"Cross_val T2E:\", Type2Error.eval({X: X_cv, Y: Y_cv}))\n",
    "        print(\"Test T2E:\",  Type2Error.eval({X: X_test, Y: Y_test}))\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print(\"Cross_val Accuracy:\", accuracy.eval({X: X_cv, Y: Y_cv}))\n",
    "        print(\"Test Accuracy:\",  accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        \n",
    "        return parameters\n",
    "        \n",
    "                                                                           \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 cost: 1.599091\n",
      "Epoch 100 cost: 0.506884\n",
      "Epoch 200 cost: 0.309904\n",
      "Epoch 300 cost: 0.218844\n",
      "Epoch 400 cost: 0.195397\n",
      "Epoch 500 cost: 0.193245\n",
      "Epoch 600 cost: 0.199414\n",
      "Epoch 700 cost: 0.190033\n",
      "Epoch 800 cost: 0.183085\n",
      "Epoch 900 cost: 0.183371\n",
      "Epoch 1000 cost: 0.183241\n",
      "Epoch 1100 cost: 0.180413\n",
      "Epoch 1200 cost: 0.176373\n",
      "Epoch 1300 cost: 0.178280\n",
      "Epoch 1400 cost: 0.180075\n",
      "Epoch 1500 cost: 0.177163\n",
      "Epoch 1600 cost: 0.178789\n",
      "Epoch 1700 cost: 0.176527\n",
      "Epoch 1800 cost: 0.177951\n",
      "Epoch 1900 cost: 0.187126\n",
      "parameters trained\n",
      "Train Accuracy: 0.9925\n",
      "Cross_val Accuracy: 0.97619\n",
      "Test Accuracy: 0.964706\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIt0UCiIi0k2hICIi3RQKIiLS7f8DPaqPTKTCzdsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2225d5d8d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#parameters = model(X_train, Y_train, X_test, Y_test, X_cv, Y_cv, learning_rate = 0.0001) # blue line\n",
    "#parameters = model(X_train, Y_train, X_test, Y_test, X_cv, Y_cv, learning_rate = 0.004)  # orange line\n",
    "parameters = model(X_train, Y_train, X_test, Y_test, X_cv, Y_cv, learning_rate = 0.0003)   # green line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
