{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('BreastCancer.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_largest_worst</th>\n",
       "      <th>texture_largest_worst</th>\n",
       "      <th>perimeter_largest_worst</th>\n",
       "      <th>area_largest_worst</th>\n",
       "      <th>smoothness_largest_worst</th>\n",
       "      <th>compactness_largest_worst</th>\n",
       "      <th>concavity_largest_worst</th>\n",
       "      <th>concave_points_largest_worst</th>\n",
       "      <th>symmetry_largest_worst</th>\n",
       "      <th>fractal_dimension_largest_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1.717544</td>\n",
       "      <td>1.088192</td>\n",
       "      <td>2.128936</td>\n",
       "      <td>1.676860</td>\n",
       "      <td>2.292337</td>\n",
       "      <td>4.564409</td>\n",
       "      <td>3.595100</td>\n",
       "      <td>2.873007</td>\n",
       "      <td>3.992012</td>\n",
       "      <td>2.637597</td>\n",
       "      <td>...</td>\n",
       "      <td>1.469161</td>\n",
       "      <td>0.983164</td>\n",
       "      <td>1.876012</td>\n",
       "      <td>1.303957</td>\n",
       "      <td>1.380992</td>\n",
       "      <td>2.301659</td>\n",
       "      <td>2.377056</td>\n",
       "      <td>2.071945</td>\n",
       "      <td>4.104329</td>\n",
       "      <td>0.868941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>-0.078686</td>\n",
       "      <td>-0.955502</td>\n",
       "      <td>-0.122599</td>\n",
       "      <td>-0.191777</td>\n",
       "      <td>-0.085343</td>\n",
       "      <td>-0.519969</td>\n",
       "      <td>-0.552050</td>\n",
       "      <td>-0.304337</td>\n",
       "      <td>1.088416</td>\n",
       "      <td>-0.604446</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266734</td>\n",
       "      <td>-0.640589</td>\n",
       "      <td>-0.264599</td>\n",
       "      <td>-0.369861</td>\n",
       "      <td>-0.607408</td>\n",
       "      <td>-0.520318</td>\n",
       "      <td>-0.606777</td>\n",
       "      <td>-0.223272</td>\n",
       "      <td>0.087678</td>\n",
       "      <td>-0.820863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>1.056372</td>\n",
       "      <td>-1.408881</td>\n",
       "      <td>0.931355</td>\n",
       "      <td>0.958219</td>\n",
       "      <td>-1.278450</td>\n",
       "      <td>-0.798500</td>\n",
       "      <td>-0.556315</td>\n",
       "      <td>-0.183985</td>\n",
       "      <td>-2.158067</td>\n",
       "      <td>-1.468425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.734664</td>\n",
       "      <td>-1.180755</td>\n",
       "      <td>0.590395</td>\n",
       "      <td>0.578577</td>\n",
       "      <td>-1.478099</td>\n",
       "      <td>-0.982004</td>\n",
       "      <td>-0.802344</td>\n",
       "      <td>-0.474595</td>\n",
       "      <td>-1.806694</td>\n",
       "      <td>-1.397234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1.411078</td>\n",
       "      <td>1.627597</td>\n",
       "      <td>1.528087</td>\n",
       "      <td>1.355759</td>\n",
       "      <td>1.787506</td>\n",
       "      <td>1.415548</td>\n",
       "      <td>1.315867</td>\n",
       "      <td>2.525095</td>\n",
       "      <td>-0.647905</td>\n",
       "      <td>1.337380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840184</td>\n",
       "      <td>1.145864</td>\n",
       "      <td>1.012983</td>\n",
       "      <td>0.733137</td>\n",
       "      <td>0.299198</td>\n",
       "      <td>0.174371</td>\n",
       "      <td>-0.138951</td>\n",
       "      <td>1.057224</td>\n",
       "      <td>-0.953257</td>\n",
       "      <td>0.447598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>-0.802285</td>\n",
       "      <td>-0.255671</td>\n",
       "      <td>-0.742378</td>\n",
       "      <td>-0.754414</td>\n",
       "      <td>-0.031305</td>\n",
       "      <td>0.533186</td>\n",
       "      <td>0.827908</td>\n",
       "      <td>-0.525197</td>\n",
       "      <td>0.884143</td>\n",
       "      <td>1.967660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.763295</td>\n",
       "      <td>0.371409</td>\n",
       "      <td>-0.598205</td>\n",
       "      <td>-0.716041</td>\n",
       "      <td>0.102109</td>\n",
       "      <td>1.465235</td>\n",
       "      <td>2.259620</td>\n",
       "      <td>0.109440</td>\n",
       "      <td>0.658253</td>\n",
       "      <td>2.533276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "78      1.717544      1.088192        2.128936   1.676860         2.292337   \n",
       "279    -0.078686     -0.955502       -0.122599  -0.191777        -0.085343   \n",
       "491     1.056372     -1.408881        0.931355   0.958219        -1.278450   \n",
       "83      1.411078      1.627597        1.528087   1.355759         1.787506   \n",
       "242    -0.802285     -0.255671       -0.742378  -0.754414        -0.031305   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave_points_mean  symmetry_mean  \\\n",
       "78           4.564409        3.595100             2.873007       3.992012   \n",
       "279         -0.519969       -0.552050            -0.304337       1.088416   \n",
       "491         -0.798500       -0.556315            -0.183985      -2.158067   \n",
       "83           1.415548        1.315867             2.525095      -0.647905   \n",
       "242          0.533186        0.827908            -0.525197       0.884143   \n",
       "\n",
       "     fractal_dimension_mean               ...                 \\\n",
       "78                 2.637597               ...                  \n",
       "279               -0.604446               ...                  \n",
       "491               -1.468425               ...                  \n",
       "83                 1.337380               ...                  \n",
       "242                1.967660               ...                  \n",
       "\n",
       "     radius_largest_worst  texture_largest_worst  perimeter_largest_worst  \\\n",
       "78               1.469161               0.983164                 1.876012   \n",
       "279             -0.266734              -0.640589                -0.264599   \n",
       "491              0.734664              -1.180755                 0.590395   \n",
       "83               0.840184               1.145864                 1.012983   \n",
       "242             -0.763295               0.371409                -0.598205   \n",
       "\n",
       "     area_largest_worst  smoothness_largest_worst  compactness_largest_worst  \\\n",
       "78             1.303957                  1.380992                   2.301659   \n",
       "279           -0.369861                 -0.607408                  -0.520318   \n",
       "491            0.578577                 -1.478099                  -0.982004   \n",
       "83             0.733137                  0.299198                   0.174371   \n",
       "242           -0.716041                  0.102109                   1.465235   \n",
       "\n",
       "     concavity_largest_worst  concave_points_largest_worst  \\\n",
       "78                  2.377056                      2.071945   \n",
       "279                -0.606777                     -0.223272   \n",
       "491                -0.802344                     -0.474595   \n",
       "83                 -0.138951                      1.057224   \n",
       "242                 2.259620                      0.109440   \n",
       "\n",
       "     symmetry_largest_worst  fractal_dimension_largest_worst  \n",
       "78                 4.104329                         0.868941  \n",
       "279                0.087678                        -0.820863  \n",
       "491               -1.806694                        -1.397234  \n",
       "83                -0.953257                         0.447598  \n",
       "242                0.658253                         2.533276  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X: 30 features per example (not including index which I excluded)\n",
    "# Y: diagnosis (M: Malignant, B: Benign) -> map M: 1, B: 0\n",
    "df.columns = ['index', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "              'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', \n",
    "              'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean', \n",
    "              'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', \n",
    "              'compactness_se', 'concavity_se', 'concave_points_se', 'symmetry_se', \n",
    "              'fractal_dimension_se', 'radius_largest_worst', 'texture_largest_worst', \n",
    "              'perimeter_largest_worst', 'area_largest_worst', 'smoothness_largest_worst', \n",
    "              'compactness_largest_worst', 'concavity_largest_worst', 'concave_points_largest_worst', \n",
    "              'symmetry_largest_worst', 'fractal_dimension_largest_worst']\n",
    "df = df.drop('index',axis =1)\n",
    "df = df.sample(frac=1) # shuffle the rows\n",
    "Y = df['diagnosis']\n",
    "Y = Y.map({'M': 1, 'B': 0})\n",
    "df = df.drop('diagnosis', axis=1)\n",
    "df = (df - df.mean(axis=0))/df.std(axis=0) # feature scaling\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 400\n",
      "number of test examples = 85\n",
      "X_train shape: (30, 400)\n",
      "Y_train shape: (1, 400)\n",
      "X_test shape: (30, 85)\n",
      "Y_test shape: (1, 85)\n",
      "X_cv shape: (30, 84)\n",
      "Y_cv shape: (1, 84)\n"
     ]
    }
   ],
   "source": [
    "X_train = df.iloc[0:400,:] # first 400 rows\n",
    "X_cv = df.iloc[400:484,:]\n",
    "X_test = df.iloc[484:569,:]\n",
    "\n",
    "Y_train = Y.iloc[0:400]\n",
    "Y_cv = Y.iloc[400:484]\n",
    "Y_test = Y.iloc[484:569]\n",
    "\n",
    "# convert to numpy arrays\n",
    "# let each column represent one data entry\n",
    "X_train = X_train.values.T\n",
    "X_cv = X_cv.values.T\n",
    "X_test = X_test.values.T\n",
    "Y_train = Y_train.values.T\n",
    "Y_cv = Y_cv.values.T\n",
    "Y_test = Y_test.values.T\n",
    "\n",
    "Y_train.shape = (1,400)\n",
    "Y_cv.shape = (1,84)\n",
    "Y_test.shape = (1,85)\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[1])) \n",
    "print (\"number of test examples = \" + str(X_test.shape[1])) \n",
    "print (\"X_train shape: \" + str(X_train.shape)) \n",
    "print (\"Y_train shape: \" + str(Y_train.shape)) \n",
    "print (\"X_test shape: \" + str(X_test.shape)) \n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "print (\"X_cv shape: \" + str(X_cv.shape)) \n",
    "print (\"Y_cv shape: \" + str(Y_cv.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    X = tf.placeholder(tf.float32, [n_x, None])\n",
    "    Y = tf.placeholder(tf.float32, [n_y, None])\n",
    "    return X,Y\n",
    "\n",
    "def initialize_parameters():\n",
    "    # input layer      : 30 nodes\n",
    "    # 1st hidden layer : 20 nodes\n",
    "    # 2nd hidden layer : 10 nodes\n",
    "    # output layer     : 1 node\n",
    "    \n",
    "    W1 = tf.get_variable('W1', [20,30], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.get_variable('b1', [20,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable('W2', [10,20], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    b2 = tf.get_variable('b2', [10,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable('W3', [1,10], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    b3 = tf.get_variable('b3', [1,1], initializer = tf.zeros_initializer())\n",
    "    \n",
    "    parameters = {'W1': W1,\n",
    "                 'b1': b1,\n",
    "                 'W2': W2,\n",
    "                 'b2': b2,\n",
    "                 'W3': W3,\n",
    "                 'b3': b3}\n",
    "    return parameters\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(W1,X), b1)\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1), b2)\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2), b3)\n",
    "    \n",
    "    return Z3\n",
    "\n",
    "def compute_cost(Z3, Y, parameters):\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    \n",
    "    #L2_regularization_cost = np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3))\n",
    "    \n",
    "    beta = 0.04\n",
    "    regularizers = tf.nn.l2_loss(W1) + tf.nn.l2_loss(W2) + tf.nn.l2_loss(W3)\n",
    "    cost = tf.reduce_mean(cost + beta*regularizers)\n",
    "    \n",
    "    #cost = cost + L2_regularization_cost\n",
    "    return cost\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64):\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    \n",
    "    # shuffle X and Y\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    \n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # last batch\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, X_cv, Y_cv, learning_rate = 0.001,\n",
    "         num_epochs = 2000, minibatch_size = 64, print_cost = True):\n",
    "    \n",
    "    ops.reset_default_graph()\n",
    "    (n_x,m) = X_train.shape\n",
    "    n_y = Y_train.shape[0]\n",
    "    costs = []\n",
    "    \n",
    "    X, Y = create_placeholders(n_x,n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3,Y, parameters)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_cost = 0\n",
    "            num_minibatches = int(m/minibatch_size)\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n",
    "            \n",
    "            for minibatch in minibatches:\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                _, minibatch_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y})\n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print('Epoch %i cost: %f' % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0 and epoch >= 0:\n",
    "                costs.append(epoch_cost)\n",
    "        \n",
    "        plt.plot(np.squeeze(costs),lw=0.5)\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.title('Learning rate='+str(learning_rate))\n",
    "        \n",
    "        parameters = sess.run(parameters)\n",
    "        print('parameters trained')\n",
    "        \n",
    "        \n",
    "        correct_prediction = tf.equal(tf.round(tf.sigmoid(Z3)), tf.round(Y))\n",
    "        \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "        \n",
    "        print(\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print(\"Cross_val Accuracy:\", accuracy.eval({X: X_cv, Y: Y_cv}))\n",
    "        print(\"Test Accuracy:\",  accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters\n",
    "        \n",
    "                                                                           \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 cost: 2.086200\n",
      "Epoch 100 cost: 0.648579\n",
      "Epoch 200 cost: 0.354533\n",
      "Epoch 300 cost: 0.260028\n",
      "Epoch 400 cost: 0.229811\n",
      "Epoch 500 cost: 0.224206\n",
      "Epoch 600 cost: 0.215676\n",
      "Epoch 700 cost: 0.211516\n",
      "Epoch 800 cost: 0.210697\n",
      "Epoch 900 cost: 0.240292\n",
      "Epoch 1000 cost: 0.212406\n",
      "Epoch 1100 cost: 0.205987\n",
      "Epoch 1200 cost: 0.209418\n",
      "Epoch 1300 cost: 0.207300\n",
      "Epoch 1400 cost: 0.204349\n",
      "Epoch 1500 cost: 0.202002\n",
      "Epoch 1600 cost: 0.202324\n",
      "Epoch 1700 cost: 0.209025\n",
      "Epoch 1800 cost: 0.206927\n",
      "Epoch 1900 cost: 0.206407\n",
      "parameters trained\n",
      "Train Accuracy: 0.985\n",
      "Cross_val Accuracy: 0.97619\n",
      "Test Accuracy: 0.976471\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16ea5b53da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = model(X_train, Y_train, X_test, Y_test, X_cv, Y_cv, learning_rate = 0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
